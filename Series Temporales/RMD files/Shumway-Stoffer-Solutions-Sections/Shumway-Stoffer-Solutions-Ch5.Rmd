```{r ch5-setup}
suppressPackageStartupMessages({
	library(astsa)
	library(tsibble)
	library(fable)
	library(feasts)
	library(dplyr)
	library(tidyr)
	library(purrr)
	library(magrittr)
	library(ggplot2)
	library(rugarch)
	library(kableExtra)
})
```

<a name="problema-5-1"></a>
**Problema 5.1** El conjunto de datos `arf` son 1000 observaciones simuladas de un modelo $ARFIMA(1, 1, 0)$ con $\phi = .75$ y $d = .4$.  
_a)_ Grafique los datos y comente.  
_b)_ Trazar el ACF y PACF de los datos y comentar.  
_c)_ Estime los parámetros y pruebe la significación de las estimaciones $\hat{\phi}$ y $\hat{d}$.  
_d)_ Explique por qué, usando los resultados de las partes _a)_ y _b)_, parecería razonable diferenciar los datos antes del análisis. Es decir, si $x_t$ representa los datos, explique por qué podríamos elegir ajustar un modelo $ARMA$ a $\nabla x_t$.  
_e)_ Trace el ACF y el PACF de $\nabla x_t$ y comente.  
_f)_ Ajuste un modelo $ARMA$ a $\nabla x_t$ y comente.  

La serie mostrada en la `r figr("p05-01-01-setup", TRUE, type="figura")` muestra los valores simulados del modelo $ARFIMA(1,1,0)$ con $\phi = .75$ y $d = .4$. 
Se observa en la serie un patrón cíclico cuyo periodo parece variar de 50 a 150 años a lo largo de la serie, alargándose el ciclo y luego haciéndose mas corto. 

```{r p05-01-01-tsplot, anchor="figura", fig.cap="Serie arf."}
arf %>%
  as_tsibble() %>%
  autoplot() +
  theme_light() +
  scale_x_continuous(name = "Tiempo",
    breaks = seq(0, 1000, by = 100),
    labels = seq(0, 1000, by = 100))
```

La ACF muestra que el proceso es de memoria larga, con autocorrelaciones importantes (con magnitudes moderadas a moderadamente pequeñas) que se extienden a valores de $h>100$, y que decrecen y crecen nuevamente una y otra vez. 
El PACF muestra que el proceso puede ser autoregresivo de segundo orden, con correlaciones significativas en $h=14$ y $h=69$.

```{r p05-01-02-acf, anchor="figura", fig.cap="ACF y PACF de la serie."}
cowplot::plot_grid(
	ACF(as_tsibble(arf), value, lag_max=100) %>%
	  autoplot() + theme_light(),
	PACF(as_tsibble(arf), value, lag_max=100) %>%
	  autoplot() + theme_light(),
	nrow=1)
```

El modelo ARFIMA estimado por selección automática basada en criterios de información tiene por parámetros los mostrados en la `r figr("p05-01-03-autoarfima", TRUE, type = "tabla")`. Se puede observar que los componentes de promedio móvil no son importantes. 
El valor para $\phi_2$ no es significativo, pero $\phi_1$ y $d$ si lo son, indicando que se trata de un modelo ARFIMA de primer orden en el componente autoregresivo, con diferencia fraccional. 
Los valores estimados para estos parámetros son muy similares a los usados para generar la serie, a partir de una distribución normal estándar.

```{r p05-01-03-autoarfima, anchor="tabla"}
arfima_estimation <- autoarfima(arf,
	method="full", arfima=NULL)

arfima_estimation$fit@fit$matcoef %>%
  as_tibble() %>%
  mutate(coef=c("$\\hat{\\phi_1}$", "$\\hat{\\phi_2}$", "$\\hat{\\theta_1}$", "$\\hat{\\theta_2}$", "$\\hat{d}$", "$\\hat{\\sigma}$"), .before = 1) %>%
  kbl(digits = c(NA, 3, 4, 2, 4),
  	escape = FALSE,
  	col.names=c("Coef.", "Estimado", "Desv. Est.", "$t$", "$p$"),
  	caption = "Coeficientes estimados por selección automática de modelo."
  )
```

Para el inciso _d)_, se observa en el gráfico temporal (`r figr("p05-01-01-tsplot", TRUE, type="figura")`) que hay cierto componente con tendencia, que se puede eliminar por medio de una diferencia. Esto, además, diminuiría la autocorrelación serial observada en la ACF mostrada en la `r figr("p05-01-02-acf", TRUE, type="figura")`.

El ACF y PACF de la primera diferencia de la serie `arf` se muestra abajo:

```{r p05-01-04-acf, anchor="figura", fig.cap="ACF y PACF de la serie diferenciada."}
cowplot::plot_grid(
	ACF(as_tsibble(diff(arf)), value, lag_max=100) %>%
	  autoplot() + theme_light(),
	PACF(as_tsibble(diff(arf)), value, lag_max=100) %>%
	  autoplot() + theme_light(),
	nrow=1)
```

Se observa de la ACF que el componente autoregresivo de primer orden resalta, con varias correlaciones pequeñas significativas. 

Se ajustan varios modelos ARMA en el siguiente fragmento de código, y se muestran los criterios de información ordenados en forma descendente de $AIC$. 
El modelo ARMA preferible según los criterios de información es el autoregresivo de primer orden, sin componente de promedio móvil.

```{r p05-01-04-model, anchor="tabla"}
mod <- as_tsibble(diff(arf)) %>%
  model(
  	mod_1 = ARIMA(value ~ 0 + pdq(1, 0, 0), stepwise = FALSE),
  	mod_2 = ARIMA(value ~ 0 + pdq(1, 0, 1), stepwise = FALSE),
  	mod_3 = ARIMA(value ~ 0 + pdq(1, 0, 2), stepwise = FALSE),
  	mod_4 = ARIMA(value ~ 0 + pdq(2, 0, 0), stepwise = FALSE),
  	mod_5 = ARIMA(value ~ 0 + pdq(2, 0, 1), stepwise = FALSE),
  	mod_6 = ARIMA(value ~ 0 + pdq(2, 0, 2), stepwise = FALSE)
  )

glance(mod) %>%
  select(.model:BIC) %>%
  mutate(.model = c("ARMA(1,0)", "ARMA(1,1)", "ARMA(1,2)", "ARMA(2,0)", "ARMA(2,1)", "ARMA(2,2)")) %>%
  arrange(AIC) %>%
  kbl(digits = c(NA, 2, 0, 2, 2, 2),
  	escape = FALSE,
  	col.names=c("Modelo", "$\\sigma^2$", "Func. Verosim.", "$AIC$", "$AICc$", "$BIC$"),
  	caption = "Criterios de información para los mdoelos ARMA ajustados.")
```

El valor estimado para el coeficiente autoregresivo es $\phi =$ `r round(tidy(select(mod, mod_1))$estimate, 3)` $\pm$ `r round(tidy(select(mod, mod_1))$std.error, 4)`, el cual es muy significativo. 
Los gráficos diagnósticos muestran que los residuales se comportan normalmente, pero se observan aun autocorrelaciones pequeñas significativas en el ACF y PACF.

```{r p05-01-05-diagnostics, anchor="tabla"}
augmented_df <- augment(select(mod, mod_1))

augmented_df %>%
  ACF(.innov, lag_max=100) %>%
  autoplot() +
    theme_light() +
    xlab("lag") + 
    ylab(latex2exp::TeX("$\\rho(s, t)$")) -> acf

augmented_df %>%
  PACF(.innov, lag_max=100) %>%
  autoplot() +
    theme_light() +
    xlab("lag") + 
    ylab(latex2exp::TeX("$\\rho(s, t)$")) -> pacf 

res_series <- augmented_df %>%
     autoplot(.resid, colour="orange") +
     geom_point(aes(y=.resid), colour="orange") +
     xlab("Tiempo") +
     ylab("Residuales") +
     theme_light() +
     geom_hline(yintercept=c(0), 
     	color=c("black"), linetype=c(1))

res_qq_plot <- augmented_df %>% 
  ggplot(aes(sample = .resid)) + 
  stat_qq() + stat_qq_line(color="red") + 
  theme_light()

cowplot::plot_grid(acf, pacf, res_series, res_qq_plot, 
  nrow=1, align="h",
  labels=c("a)", "b)", "c)", "d)"), 
  label_size=11, 
  label_fontface="italic")
```

**Problema 5.3** Grafique la serie de temperatura global, `globtemp`, y luego pruebe si hay una raíz unitaria versus la alternativa de que el proceso es estacionario usando las tres pruebas: DF, ADF y PP, discutidas en el Ejemplo 5.3. Comente.

Los detalles de la prueba DF y ADF en el paquete `tseries` indican que la regresión general que se hace sobre la serie incluye un termino constante y uno con tendencia lineal, además de los $k$ retrasos usados para considerar el proceso autoregresivo. 
Esto implica, que la hipótesis nula prueba si el proceso es uno con tendencia lineal y deriva (prueba Df), y la alternativa estipula que se trata de un paseo aleatorio con componentes de tendencia lineal y deriva.

En el <a href="/Series%20Temporales/output/Shunway-Stoffer-Solutions.md#problema-3-33">Problema 3.33</a> vimos que el modelo autoregresivo mas adecuado para la serie involucra uno de orden $p=2$, por lo que se usa $k=2$ para la prueba ADF. 

```{r p05-03-01}
list(
	  df=tseries::adf.test(globtemp, k=0),
	  adf=tseries::adf.test(globtemp, k=2),
	  pp=tseries::pp.test(globtemp)) |>
  map(broom::tidy) |>
  list_rbind() |>
  select(method, statistic:parameter) |>
  kbl(
    col.names=c("Prueba", "Estadístico", "$p$", "df"),
    escape=FALSE, 
    caption="Estadísticos de las pruebas de Raíz unitaria para estacionaridad."
  )
```

Los resultados de aplicar las pruebas de raíz unitaria de DF y PP muestran que la serie de temperatura global es estacionaria ($p<0{,}05$), dado que se rechaza la hipótesis nula de raíz unitaria. Esto es de esperar, dado que ambas pruebas analizan el mismo esquema de dependencia. 
Por otro lado, la ADF resulta en aceptación de la hipótesis nula, indicando que la serie sigue un paseo aleatorio con deriva.

La discrepancia entre los resultados de la prueba DF y la prueba ADF resulta de que, al considerar los retrasos hasta $h=2$, se captura la dependencia de la serie con respecto a los retrasos en $t-1$ y $t-2$, haciendo innecesario el termino extra para $x_{t-1}$. 
Al usar $k=1$ en la prueba ADF, el resultado sigue siendo mantener la hipótesis nula, (aunque el resultado es marginal), lo cual podría indicar que la serie diferenciada se trata de un proceso $AR(1)$ con una tendencia lineal y deriva ($DF_\gamma =$ `r round(tseries::adf.test(globtemp, k=1)$statistic, 3)`, $p=$ `r round(tseries::adf.test(globtemp, k=1)$p.value, 4)`). 

Es interesante que al realizar las pruebas sobre la serie `globtemp` luego de realizar una primera diferencia, todas las pruebas son significativas, indicadno que la serie diferenciada si es estacioanria. 
Además, la  prueba ADF se hace usando $k=1$, lo cual toma en cuenta la autocorrelación con respecto al retraso $h=2$ en la serie sin diferenciar. 

```{r p05-03-02}
list(
	  df=tseries::adf.test(diff(globtemp), k=0),
	  adf=tseries::adf.test(diff(globtemp), k=1),
	  pp=tseries::pp.test(diff(globtemp))) |>
  map(broom::tidy) |>
  list_rbind() |>
  select(method, statistic:parameter) |>
  kbl(
    col.names=c("Prueba", "Estadístico", "$p$", "df"),
    escape=FALSE, 
    caption="Estadísticos de las pruebas de Raíz unitaria para estacionaridad."
  )
```

<a name="problema-5-7"></a>
**Problema 5.7** El paquete `stats` de R contiene los precios de cierre diarios de los cuatro principales índices bursátiles europeos; escriba `help(EuStockMarkets)` para obtener más detalles. Ajuste un modelo $GARCH$ a los rendimientos de una de estas series y discuta sus hallazgos. (Nota: el conjunto de datos contiene valores reales y no retornos. Por lo tanto, los datos deben transformarse antes del ajuste del modelo).

```{r p05-07-01-cleansing}
EU_SMI <- EuStockMarkets[, "SMI"] %>% 
  as_tsibble() %>%
  mutate(dates = lubridate::date(index), .before = 2) %>%
  index_by(dates) %>%
  summarise(
    smi_difflog = value
  ) %>%
  mutate(smi_difflog = difference(log(smi_difflog))) %>%
  slice(-1) %>%
  complete(dates = seq(min(dates), max(dates), by = "day")) %>%
  mutate(smi_difflog=zoo::na.approx(smi_difflog)) %>%
  as_tsibble()
```

Para el análisis se seleccionó el indice bursátil correspondiente a Suiza (SMI). Al revisar la serie se nota de inmediato que la serie contiene `NA`, introducidos de forma alternativa cada 2 a 3 días. Estos datos faltantes se imputaron usando interpolación lineal.

```{r p05-07-02-data, anchor="figura", fig.cap="Indice bursátil de Suiza.", fig.height=5, fig.width=12}
cowplot::plot_grid(
	EuStockMarkets[, "SMI"] %>% 
    as_tsibble() %>%
	  autoplot(, colour="dodgerblue3") +
	    theme_light() +
	    xlab("") + ylab("Precios de cierre diario") +
	    ggtitle("Indice bursátil Europeo (Suiza SMI)"),
	EU_SMI %>%
	  autoplot(smi_difflog, colour="dodgerblue3") +
	    theme_light() +
	    xlab("") + ylab("Retornos") +
	    ggtitle("Retornos logarítmicos del SMI."),
	nrow=1)
```

El indice bursátil correspondiente a Suiza (SMI), el cual se muestra en la `r figr("p05-07-02-data", TRUE, type = "figura")`, junto a los retornos calculados a partir de la misma. 
La serie tiene una tendencia creciente clara que se elimina al calcular los retornos, con caídas importantes durante todo el año 1994, y a la mitad del año 1997. Es en estos momentos es que se observan los _clusters_ de volatilidad más importantes de la serie de retornos. 

La ACF y PACF muestran que los retornos parecen ser generados por un proceso autoregresivo de primer o segundo orden en el componente ARMA, y se observan múltiples correlaciones pequeñas, pero significativas, que pueden resultar de la volatilidad cambiante.  
La volatilidad se observa a la derecha en la misma figura, la cual se calcula usando una ventana de un mes, y presenta un comportamiento bastante fluctuante, con crestas particularmente grandes durante los años 1994 y 1997.

```{r p05-07-03-acf-pacf, anchor="figura", fig.cap="Funciones de autocorrelación y autocorrelación parcial para los retornos (a la izquierda) y volatilidad mensual de los retornos.", fig.height=7, fig.width=10}
monthly_aggregates <- EU_SMI %>%
  index_by(year_month = ~ yearmonth(.)) %>%
  summarise(
  	month_var = var(smi_difflog, na.rm = TRUE),
    month_mean_return = mean(smi_difflog ** 2, na.rm = TRUE))

cowplot::plot_grid(
	cowplot::plot_grid(
		EU_SMI %>%
		  ACF(smi_difflog, lag_max=100) %>%
		  autoplot() +
		    xlab("h") +
		    ylab("ACF") +
		    theme_light(),
		EU_SMI %>%
		  PACF(smi_difflog, lag_max=100) %>%
		  autoplot() +
		    xlab("h") +
		    ylab("PACF") +
		    theme_light(),
		ncol=1), 
	monthly_aggregates %>%
	  autoplot(month_var, colour = "dodgerblue4") +
      theme_light() +
      ylab("Volatilidad") +
      xlab(""),
  nrow=1)
```

El siguiente fragmento de código muestra los resultados de la prueba Arch por multiplicadores de Lagrange, al descomponer la varianza de la serie e identificar si sus rezagos son significativos:

```{r p05-07-04-var-lags}
arch_test <- EU_SMI %$%
  FinTS::ArchTest(smi_difflog, lags = 4, demean = FALSE)
```

de lo que se obtiene que la serie tiene efectos Arch significativos ($\chi^2=$ `r round(arch_test$statistic, 2)`, $p=$ `r round(arch_test$p.value, 4)` ), y que existe una correlación importante entre la varianza y los retornos cuadrados. 

Se procede a ajustar modelos GARCH para la volatilidad, con componente $ARCH(1)$ y $ARCH(2)$ solamente, y con volatilidad independiente de sus retrasos, y regresada sobre retrasos $h=1$ y $2$. Además, se prueban estos modelos usando la posibilidad de un modelo ARMA para la media con componente autoregresivo de primer o segundo orden. 

```{r p05-07-05-models-fitting}
ARMA_mod <- rep(c("ARMA(1, 0)", "ARMA(2, 0)"), each=4)
GARCH_mod <- rep(c("GARCH(1,0)", "GARCH(1,1)", "GARCH(2,1)", "GARCH(2,2)"), 2)
arma_pars <- rep(list(fisrt_order=c(1,0), second_order=c(2,0)), each=4)
garch_mod_pars <- rep(list(c(1, 0), c(1, 1), c(2, 1), c(2, 2)), 2)

garch_fitting <- tibble(
	ARMA_mod, GARCH_mod,
	arma_mod=arma_pars,
  garch_mod=garch_mod_pars) %>%
  mutate(
  	garch_mods_spec=map2(
	    arma_mod, garch_mod,
      ~ugarchspec(
   	    mean.model = list(
   		    armaOrder=.x, 
   		    include.mean = FALSE),
        variance.model=list(model = "sGARCH", garchOrder=.y),
        distribution.model = "norm")
    ),
    garch_mods_fit=map(garch_mods_spec,
      ~ugarchfit(., EU_SMI)),
    convergence=map_dbl(garch_mods_fit, convergence)
  ) %>%
  filter(convergence == 0)
```

En total, se ajustan 8 modelos, de los cuales solo el modelo $GARCH(1,0)$ con componente $ARMA(1,0)$ para la media, fallo en converger. 
En la tabla `r figr("p05-07-06-criteria-inf", TRUE, type = "tabla")` se muestran los resultados de los criterios de información para el resto de los modelos ajustados, donde se observa que los mejores modelos, de acuerdo al AIC, son los $GARCH(2,2)$, tanto para el componente $ARMA(1,0)$ como para $ARMA(2,0)$; seguido de los modelos con componente $ARMA(2,0)$ y componente $GARCH(1, 1)$ y $GARCH(2, 1)$. 
La misma tendencia se sigue del resto de los criterios de información mostrados en la tabla. 

```{r p05-07-06-criteria-inf, anchor="tabla"}
garch_fitting %>%
  mutate(glanced=map(garch_mods_fit, infocriteria), .after=2) %>% 
  unnest(glanced) %>% 
  mutate(criteria=rep(c("AIC", "BIC", "Shibata", "Hannan-Quinn"), 7), .after=2) %>%
  select(1:4) %>%
  spread(key="criteria", value=4) %>%
  arrange(AIC) %>%
  slice(1:5) %>%
  kbl(digits = 3,
    caption="Criterios de información para 5 de los modelos GARCH ajustados.")
```

Sin embargo, al verificar los coeficientes de los modelos $GARCH(2,2)$ y $GARCH(2,1)$, se obtiene que los coeficientes $\\alpha_2$ no son significativos (resultado no mostrado). 
Es por ello que se escoge el modelo $GARCH(1,1)$ con componente $ARMA(2,0)$, dados los criterios de información mostrados antes. 
Los coeficientes de este modelo se muestran a continuación.

```{r p05-07-07-coef-est, anchor="tabla"}
garch_fitting %>%
  mutate(tidied=map(garch_mods_fit, 
    \(x) {
    x@fit$matcoef %>%
      as_tibble()
  }), .after=2) %>% 
  unnest(tidied) %>%
  filter(ARMA_mod == "ARMA(2, 0)" & GARCH_mod == "GARCH(1,1)") %>%
  mutate(
  	criteria=c("$\\phi_1$", "$\\phi_2$", "$\\alpha_0$", "$\\alpha_1$", "$\\beta$"),
  	.after=2) %>%
  select(criteria:`Pr(>|t|)`) %>%
  kbl(digits = c(NA, 6, 7, 2, 4),
  	escape=FALSE,
  	col.names=c("Coef.", "Estimado", "Desv. Estand.", "$t$", "$p$"),
    caption="Coeficientes estimados para el modelo ARMA(2,0) con GARCH(1,1).")
```

El modelo final escogido se escribe entonces:

$$
\begin{aligned}
  r_t &= \phi_1 r_{t-1} + \phi_2 r_{t-2} + \sigma_t\epsilon_t \\
  \sigma_t &= \alpha_0 + \alpha_1 r_{t-1} + \beta \sigma_{t-1}
\end{aligned}
$$

donde $\epsilon_t \sim N(0, 1)$. 
Los residuales, tal como se observan en la `r figr("p05-07-08-residuals", TRUE, type = "figura")`, donde se observa que ya no hay correlaciones importantes en las ACF y PACF, pero los residuales no se distribuyen normalmente, sino que parecen seguir una $t$-Student simétrica. 

```{r p05-07-08-residuals, anchor="figura", fig.cap="Gráficos diagnósticos de residuales."}
residuals_garch <- garch_fitting %>%
  filter(ARMA_mod == "ARMA(2, 0)" & GARCH_mod == "GARCH(1,1)") %$%
  residuals(garch_mods_fit[[1]]) %>%
  zoo::fortify.zoo() %>%
  as_tsibble()

cowplot::plot_grid(
  autoplot(residuals_garch, ., colour="orange") +
    theme_light() + xlab("") + ylab("Innovaciones"),
  residuals_garch %>% 
    ggplot(aes(sample = .)) + 
    stat_qq() + stat_qq_line(color="dodgerblue") + 
    theme_light(),
  cowplot::plot_grid(
    ACF(residuals_garch, ., lag_max=50) %>%
      autoplot() + theme_light() +
      xlab("lag") + ylab("ACF"),
    PACF(residuals_garch, ., lag_max=50) %>%
      autoplot() + theme_light() +
      xlab("lag") + ylab("PACF"),
    nrow=2
  ),
  nrow=1
)
```

Al realizar un ultimo ajuste del modelo $GARCH(1,1)$ con modelo para la media $ARMA(2,0)$, y usando como modelo de distribución una $t$-Student, se obtienen criterios de información menores que los encontrados para los modelos anteriores, indicando una preferencia por el nuevo modelo. 
Los coeficientes estimados se muestran en la siguiente tabla:

```{r p05-07-09-final-fit}
final_spec <- ugarchspec(
  mean.model = list(
    armaOrder=c(2, 0), 
   	include.mean = FALSE),
  variance.model=list(
  	model = "sGARCH",
  	garchOrder=c(1,1)),
  distribution.model = "std")

final_fit <- ugarchfit(final_spec, EU_SMI)
final_coefs <- final_fit@fit$matcoef

final_coefs %>%
  as_tibble() %>%
  mutate(Coef=c("$\\phi_1$", "$\\phi_2$", "$\\alpha_0$", "$\\alpha_1$", "$\\beta$", "shape"), .before=1) %>%
  kbl(digits = c(NA, 5, 6, 2, 4),
  	escape=FALSE,
  	col.names=c("Coef.", "Estimado", "Desv. Estand.", "$t$", "$p$"),
    caption="Coeficientes estimados para el modelo ARMA(2,0) con GARCH(1,1)."
  )
```

De los valores de probabilidad se tiene que en este caso, el modelo no necesita de términos retrasados de la volatilidad, dado que $\\beta$ no es significativamente distinto de cero, por lo que el modelo se puede escribir como uno con solo componente $Arch(1)$:

$$
\begin{aligned}
  r_t &= `r round(final_coefs[1,1], 3)`_{(`r round(final_coefs[1,2], 3)`)} r_{t-1} + `r round(final_coefs[2,1], 3)`_{(`r round(final_coefs[2,2], 3)`)} r_{t-2} + \sigma_t\epsilon_t \\
  \sigma_t &= `r round(final_coefs[3,1], 5)`_{(`r round(final_coefs[3,2], 6)`)} + `r round(final_coefs[4,1], 3)`_{(`r round(final_coefs[4,2], 3)`)} r_{t-1}
\end{aligned}
$$

con $\epsilon \sim t(\sim 5)$. 
El gráfico de los retornos versus la volatilidad muestra que el modelo es capaz de toma en cuenta las desviaciones en la serie; y el gráfico _QQ_ muestra que al usar como modelo teórico la distribución $t(5)$, las observaciones se ajustan muy bien a la recta.

```{r p05-07-10-volatility-plot}
residuals_garch <- residuals(final_fit) %>%
  zoo::fortify.zoo() %>%
  as_tsibble()

cowplot::plot_grid(
  EU_SMI %>%
    mutate(abs_returns = abs(smi_difflog)) %>%
    autoplot(abs_returns, colour="200", alpha = .6) +
    autolayer(sigma(final_fit) %>%
      zoo::fortify.zoo() %>%
      as_tsibble(), ., colour="dodgerblue", linewidth = .5) +
    theme_light() +
    ylab("Volatilidad") + xlab(""),
  residuals_garch %>% 
    ggplot(aes(sample = .)) + 
    stat_qq(distribution=stats::qt,
    	dparams=list(df=4.97)) + 
    stat_qq_line(distribution=stats::qt,
    	dparams=list(df=4.97),
    	color="dodgerblue") + 
    theme_light(),
    nrow=1
)
```